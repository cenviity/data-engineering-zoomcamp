{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FHV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y0/5f2jwbwn27ng96snkjkltj6h0000gn/T/ipykernel_14386/1754371005.py:3: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_fhv = pd.concat((df_fhv, pd.read_parquet(f\"~/downloads/fhv_tripdata_2019-{month:02}.parquet\")))\n",
      "/var/folders/y0/5f2jwbwn27ng96snkjkltj6h0000gn/T/ipykernel_14386/1754371005.py:3: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_fhv = pd.concat((df_fhv, pd.read_parquet(f\"~/downloads/fhv_tripdata_2019-{month:02}.parquet\")))\n",
      "/var/folders/y0/5f2jwbwn27ng96snkjkltj6h0000gn/T/ipykernel_14386/1754371005.py:3: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_fhv = pd.concat((df_fhv, pd.read_parquet(f\"~/downloads/fhv_tripdata_2019-{month:02}.parquet\")))\n",
      "/var/folders/y0/5f2jwbwn27ng96snkjkltj6h0000gn/T/ipykernel_14386/1754371005.py:3: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_fhv = pd.concat((df_fhv, pd.read_parquet(f\"~/downloads/fhv_tripdata_2019-{month:02}.parquet\")))\n",
      "/var/folders/y0/5f2jwbwn27ng96snkjkltj6h0000gn/T/ipykernel_14386/1754371005.py:3: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_fhv = pd.concat((df_fhv, pd.read_parquet(f\"~/downloads/fhv_tripdata_2019-{month:02}.parquet\")))\n",
      "/var/folders/y0/5f2jwbwn27ng96snkjkltj6h0000gn/T/ipykernel_14386/1754371005.py:3: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_fhv = pd.concat((df_fhv, pd.read_parquet(f\"~/downloads/fhv_tripdata_2019-{month:02}.parquet\")))\n",
      "/var/folders/y0/5f2jwbwn27ng96snkjkltj6h0000gn/T/ipykernel_14386/1754371005.py:3: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_fhv = pd.concat((df_fhv, pd.read_parquet(f\"~/downloads/fhv_tripdata_2019-{month:02}.parquet\")))\n",
      "/var/folders/y0/5f2jwbwn27ng96snkjkltj6h0000gn/T/ipykernel_14386/1754371005.py:3: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_fhv = pd.concat((df_fhv, pd.read_parquet(f\"~/downloads/fhv_tripdata_2019-{month:02}.parquet\")))\n",
      "/var/folders/y0/5f2jwbwn27ng96snkjkltj6h0000gn/T/ipykernel_14386/1754371005.py:3: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_fhv = pd.concat((df_fhv, pd.read_parquet(f\"~/downloads/fhv_tripdata_2019-{month:02}.parquet\")))\n",
      "/var/folders/y0/5f2jwbwn27ng96snkjkltj6h0000gn/T/ipykernel_14386/1754371005.py:3: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_fhv = pd.concat((df_fhv, pd.read_parquet(f\"~/downloads/fhv_tripdata_2019-{month:02}.parquet\")))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropOff_datetime</th>\n",
       "      <th>PUlocationID</th>\n",
       "      <th>DOlocationID</th>\n",
       "      <th>SR_Flag</th>\n",
       "      <th>Affiliated_base_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00001</td>\n",
       "      <td>2019-01-01 00:30:00</td>\n",
       "      <td>2019-01-01 02:51:55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00001</td>\n",
       "      <td>2019-01-01 00:45:00</td>\n",
       "      <td>2019-01-01 00:54:49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00001</td>\n",
       "      <td>2019-01-01 00:15:00</td>\n",
       "      <td>2019-01-01 00:54:52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00008</td>\n",
       "      <td>2019-01-01 00:19:00</td>\n",
       "      <td>2019-01-01 00:39:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00008</td>\n",
       "      <td>2019-01-01 00:27:00</td>\n",
       "      <td>2019-01-01 00:37:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dispatching_base_num     pickup_datetime    dropOff_datetime  PUlocationID  \\\n",
       "0               B00001 2019-01-01 00:30:00 2019-01-01 02:51:55           NaN   \n",
       "1               B00001 2019-01-01 00:45:00 2019-01-01 00:54:49           NaN   \n",
       "2               B00001 2019-01-01 00:15:00 2019-01-01 00:54:52           NaN   \n",
       "3               B00008 2019-01-01 00:19:00 2019-01-01 00:39:00           NaN   \n",
       "4               B00008 2019-01-01 00:27:00 2019-01-01 00:37:00           NaN   \n",
       "\n",
       "   DOlocationID  SR_Flag Affiliated_base_number  \n",
       "0           NaN      NaN                 B00001  \n",
       "1           NaN      NaN                 B00001  \n",
       "2           NaN      NaN                 B00001  \n",
       "3           NaN      NaN                 B00008  \n",
       "4           NaN      NaN                 B00008  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fhv = pd.DataFrame()\n",
    "for month in range(1, 13):\n",
    "    df_fhv = pd.concat((df_fhv, pd.read_parquet(f\"~/downloads/fhv_tripdata_2019-{month:02}.parquet\")))\n",
    "\n",
    "df_fhv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropOff_datetime</th>\n",
       "      <th>PUlocationID</th>\n",
       "      <th>DOlocationID</th>\n",
       "      <th>SR_Flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>43261276</td>\n",
       "      <td>43261276</td>\n",
       "      <td>4.123719e+07</td>\n",
       "      <td>4.253757e+07</td>\n",
       "      <td>5.383635e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2019-04-12 01:01:10.482539</td>\n",
       "      <td>2019-04-12 06:34:40.116056</td>\n",
       "      <td>1.913270e+02</td>\n",
       "      <td>1.825172e+02</td>\n",
       "      <td>1.903464e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>2019-01-01 00:01:42</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2019-01-16 10:20:22</td>\n",
       "      <td>2019-01-16 10:42:34</td>\n",
       "      <td>1.290000e+02</td>\n",
       "      <td>1.070000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2019-01-30 08:41:19</td>\n",
       "      <td>2019-01-30 09:02:34</td>\n",
       "      <td>2.340000e+02</td>\n",
       "      <td>2.170000e+02</td>\n",
       "      <td>2.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2019-07-02 08:59:18.750000</td>\n",
       "      <td>2019-07-02 12:24:37</td>\n",
       "      <td>2.640000e+02</td>\n",
       "      <td>2.650000e+02</td>\n",
       "      <td>2.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2019-12-31 23:59:59</td>\n",
       "      <td>5201-09-11 14:03:07</td>\n",
       "      <td>2.650000e+02</td>\n",
       "      <td>2.650000e+02</td>\n",
       "      <td>4.300000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.410937e+01</td>\n",
       "      <td>8.632832e+01</td>\n",
       "      <td>1.150658e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  pickup_datetime            dropOff_datetime  PUlocationID  \\\n",
       "count                    43261276                    43261276  4.123719e+07   \n",
       "mean   2019-04-12 01:01:10.482539  2019-04-12 06:34:40.116056  1.913270e+02   \n",
       "min           2019-01-01 00:00:00         2019-01-01 00:01:42  0.000000e+00   \n",
       "25%           2019-01-16 10:20:22         2019-01-16 10:42:34  1.290000e+02   \n",
       "50%           2019-01-30 08:41:19         2019-01-30 09:02:34  2.340000e+02   \n",
       "75%    2019-07-02 08:59:18.750000         2019-07-02 12:24:37  2.640000e+02   \n",
       "max           2019-12-31 23:59:59         5201-09-11 14:03:07  2.650000e+02   \n",
       "std                           NaN                         NaN  8.410937e+01   \n",
       "\n",
       "       DOlocationID       SR_Flag  \n",
       "count  4.253757e+07  5.383635e+06  \n",
       "mean   1.825172e+02  1.903464e+00  \n",
       "min    0.000000e+00  1.000000e+00  \n",
       "25%    1.070000e+02  1.000000e+00  \n",
       "50%    2.170000e+02  2.000000e+00  \n",
       "75%    2.650000e+02  2.000000e+00  \n",
       "max    2.650000e+02  4.300000e+01  \n",
       "std    8.632832e+01  1.150658e+00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fhv.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 43261276 entries, 0 to 2044195\n",
      "Data columns (total 7 columns):\n",
      " #   Column                  Dtype         \n",
      "---  ------                  -----         \n",
      " 0   dispatching_base_num    object        \n",
      " 1   pickup_datetime         datetime64[us]\n",
      " 2   dropOff_datetime        datetime64[us]\n",
      " 3   PUlocationID            float64       \n",
      " 4   DOlocationID            float64       \n",
      " 5   SR_Flag                 float64       \n",
      " 6   Affiliated_base_number  object        \n",
      "dtypes: datetime64[us](2), float64(3), object(2)\n",
      "memory usage: 2.6+ GB\n"
     ]
    }
   ],
   "source": [
    "df_fhv.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fhv_cast = df_fhv.convert_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 43261276 entries, 0 to 2044195\n",
      "Data columns (total 7 columns):\n",
      " #   Column                  Dtype         \n",
      "---  ------                  -----         \n",
      " 0   dispatching_base_num    string        \n",
      " 1   pickup_datetime         datetime64[us]\n",
      " 2   dropOff_datetime        datetime64[us]\n",
      " 3   PUlocationID            Int64         \n",
      " 4   DOlocationID            Int64         \n",
      " 5   SR_Flag                 Int64         \n",
      " 6   Affiliated_base_number  string        \n",
      "dtypes: Int64(3), datetime64[us](2), string(2)\n",
      "memory usage: 2.7 GB\n"
     ]
    }
   ],
   "source": [
    "df_fhv_cast.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m year \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m2019\u001b[39m, \u001b[38;5;241m2020\u001b[39m]:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m month \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m13\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m         df_yellow \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_yellow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m~/downloads/yellow_tripdata_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43myear\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmonth\u001b[49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[38;5;124;43m02\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.parquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m df_yellow\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/data-engineering-zoomcamp-2024/.venv/lib/python3.11/site-packages/pandas/core/reshape/concat.py:393\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    378\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    380\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[1;32m    381\u001b[0m     objs,\n\u001b[1;32m    382\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m    391\u001b[0m )\n\u001b[0;32m--> 393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/data-engineering-zoomcamp-2024/.venv/lib/python3.11/site-packages/pandas/core/reshape/concat.py:682\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m obj_labels\u001b[38;5;241m.\u001b[39mget_indexer(new_labels)\n\u001b[1;32m    680\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[0;32m--> 682\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[43mconcatenate_managers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmgrs_indexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcat_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbm_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    686\u001b[0m     new_data\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[0;32m~/data-engineering-zoomcamp-2024/.venv/lib/python3.11/site-packages/pandas/core/internals/concat.py:166\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m    163\u001b[0m unit \u001b[38;5;241m=\u001b[39m join_units[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    164\u001b[0m blk \u001b[38;5;241m=\u001b[39m unit\u001b[38;5;241m.\u001b[39mblock\n\u001b[0;32m--> 166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m_is_uniform_join_units\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjoin_units\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    167\u001b[0m     vals \u001b[38;5;241m=\u001b[39m [ju\u001b[38;5;241m.\u001b[39mblock\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mfor\u001b[39;00m ju \u001b[38;5;129;01min\u001b[39;00m join_units]\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mis_extension:\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;66;03m# _is_uniform_join_units ensures a single dtype, so\u001b[39;00m\n\u001b[1;32m    171\u001b[0m         \u001b[38;5;66;03m#  we can use np.concatenate, which is more performant\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[38;5;66;03m# expected \"Union[_SupportsArray[dtype[Any]],\u001b[39;00m\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;66;03m# _NestedSequence[_SupportsArray[dtype[Any]]]]\"\u001b[39;00m\n",
      "File \u001b[0;32m~/data-engineering-zoomcamp-2024/.venv/lib/python3.11/site-packages/pandas/core/internals/concat.py:597\u001b[0m, in \u001b[0;36m_is_uniform_join_units\u001b[0;34m(join_units)\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;66;03m# exclude cases where a) ju.block is None or b) we have e.g. Int64+int64\u001b[39;00m\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mtype\u001b[39m(ju\u001b[38;5;241m.\u001b[39mblock) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(first) \u001b[38;5;28;01mfor\u001b[39;00m ju \u001b[38;5;129;01min\u001b[39;00m join_units)\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;66;03m# e.g. DatetimeLikeBlock can be dt64 or td64, but these are not uniform\u001b[39;00m\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m    588\u001b[0m         ju\u001b[38;5;241m.\u001b[39mblock\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m first\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    589\u001b[0m         \u001b[38;5;66;03m# GH#42092 we only want the dtype_equal check for non-numeric blocks\u001b[39;00m\n\u001b[1;32m    590\u001b[0m         \u001b[38;5;66;03m#  (for now, may change but that would need a deprecation)\u001b[39;00m\n\u001b[1;32m    591\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m ju\u001b[38;5;241m.\u001b[39mblock\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miub\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    592\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m ju \u001b[38;5;129;01min\u001b[39;00m join_units\n\u001b[1;32m    593\u001b[0m     )\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# no blocks that would get missing values (can lead to type upcasts)\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# unless we're an extension dtype.\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mall\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m ju\u001b[38;5;241m.\u001b[39mis_na \u001b[38;5;129;01mor\u001b[39;00m ju\u001b[38;5;241m.\u001b[39mblock\u001b[38;5;241m.\u001b[39mis_extension \u001b[38;5;28;01mfor\u001b[39;00m ju \u001b[38;5;129;01min\u001b[39;00m join_units)\n\u001b[1;32m    598\u001b[0m )\n",
      "File \u001b[0;32m~/data-engineering-zoomcamp-2024/.venv/lib/python3.11/site-packages/pandas/core/internals/concat.py:597\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;66;03m# exclude cases where a) ju.block is None or b) we have e.g. Int64+int64\u001b[39;00m\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mtype\u001b[39m(ju\u001b[38;5;241m.\u001b[39mblock) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(first) \u001b[38;5;28;01mfor\u001b[39;00m ju \u001b[38;5;129;01min\u001b[39;00m join_units)\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;66;03m# e.g. DatetimeLikeBlock can be dt64 or td64, but these are not uniform\u001b[39;00m\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m    588\u001b[0m         ju\u001b[38;5;241m.\u001b[39mblock\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m first\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    589\u001b[0m         \u001b[38;5;66;03m# GH#42092 we only want the dtype_equal check for non-numeric blocks\u001b[39;00m\n\u001b[1;32m    590\u001b[0m         \u001b[38;5;66;03m#  (for now, may change but that would need a deprecation)\u001b[39;00m\n\u001b[1;32m    591\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m ju\u001b[38;5;241m.\u001b[39mblock\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miub\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    592\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m ju \u001b[38;5;129;01min\u001b[39;00m join_units\n\u001b[1;32m    593\u001b[0m     )\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# no blocks that would get missing values (can lead to type upcasts)\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# unless we're an extension dtype.\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mall\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mju\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_na\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m ju\u001b[38;5;241m.\u001b[39mblock\u001b[38;5;241m.\u001b[39mis_extension \u001b[38;5;28;01mfor\u001b[39;00m ju \u001b[38;5;129;01min\u001b[39;00m join_units)\n\u001b[1;32m    598\u001b[0m )\n",
      "File \u001b[0;32mproperties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/data-engineering-zoomcamp-2024/.venv/lib/python3.11/site-packages/pandas/core/internals/concat.py:418\u001b[0m, in \u001b[0;36mJoinUnit.is_na\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(val) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m isna(val):\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;66;03m# ideally isna_all would do this short-circuiting\u001b[39;00m\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 418\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mall\u001b[39m(isna_all(row) \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m values)\n",
      "File \u001b[0;32m~/data-engineering-zoomcamp-2024/.venv/lib/python3.11/site-packages/pandas/core/internals/concat.py:418\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(val) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m isna(val):\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;66;03m# ideally isna_all would do this short-circuiting\u001b[39;00m\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 418\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[43misna_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m values)\n",
      "File \u001b[0;32m~/data-engineering-zoomcamp-2024/.venv/lib/python3.11/site-packages/pandas/core/dtypes/missing.py:794\u001b[0m, in \u001b[0;36misna_all\u001b[0;34m(arr)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    788\u001b[0m     \u001b[38;5;66;03m# error: Incompatible types in assignment (expression has type \"Callable[[Any],\u001b[39;00m\n\u001b[1;32m    789\u001b[0m     \u001b[38;5;66;03m# Any]\", variable has type \"ufunc\")\u001b[39;00m\n\u001b[1;32m    790\u001b[0m     checker \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: _isna_array(  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         x, inf_as_na\u001b[38;5;241m=\u001b[39mINF_AS_NA\n\u001b[1;32m    792\u001b[0m     )\n\u001b[0;32m--> 794\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m    795\u001b[0m     checker(arr[i : i \u001b[38;5;241m+\u001b[39m chunk_len])\u001b[38;5;241m.\u001b[39mall() \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, total_len, chunk_len)\n\u001b[1;32m    796\u001b[0m )\n",
      "File \u001b[0;32m~/data-engineering-zoomcamp-2024/.venv/lib/python3.11/site-packages/pandas/core/dtypes/missing.py:795\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    788\u001b[0m     \u001b[38;5;66;03m# error: Incompatible types in assignment (expression has type \"Callable[[Any],\u001b[39;00m\n\u001b[1;32m    789\u001b[0m     \u001b[38;5;66;03m# Any]\", variable has type \"ufunc\")\u001b[39;00m\n\u001b[1;32m    790\u001b[0m     checker \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: _isna_array(  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         x, inf_as_na\u001b[38;5;241m=\u001b[39mINF_AS_NA\n\u001b[1;32m    792\u001b[0m     )\n\u001b[1;32m    794\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[0;32m--> 795\u001b[0m     \u001b[43mchecker\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk_len\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mall() \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, total_len, chunk_len)\n\u001b[1;32m    796\u001b[0m )\n",
      "File \u001b[0;32m~/data-engineering-zoomcamp-2024/.venv/lib/python3.11/site-packages/pandas/core/dtypes/missing.py:790\u001b[0m, in \u001b[0;36misna_all.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    785\u001b[0m     checker \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39masarray(x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi8\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;241m==\u001b[39m iNaT  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    788\u001b[0m     \u001b[38;5;66;03m# error: Incompatible types in assignment (expression has type \"Callable[[Any],\u001b[39;00m\n\u001b[1;32m    789\u001b[0m     \u001b[38;5;66;03m# Any]\", variable has type \"ufunc\")\u001b[39;00m\n\u001b[0;32m--> 790\u001b[0m     checker \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43m_isna_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[assignment]\u001b[39;49;00m\n\u001b[1;32m    791\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minf_as_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mINF_AS_NA\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m    795\u001b[0m     checker(arr[i : i \u001b[38;5;241m+\u001b[39m chunk_len])\u001b[38;5;241m.\u001b[39mall() \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, total_len, chunk_len)\n\u001b[1;32m    796\u001b[0m )\n",
      "File \u001b[0;32m~/data-engineering-zoomcamp-2024/.venv/lib/python3.11/site-packages/pandas/core/dtypes/missing.py:292\u001b[0m, in \u001b[0;36m_isna_array\u001b[0;34m(values, inf_as_na)\u001b[0m\n\u001b[1;32m    290\u001b[0m     result \u001b[38;5;241m=\u001b[39m _isna_recarray_dtype(values, inf_as_na\u001b[38;5;241m=\u001b[39minf_as_na)\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_string_or_object_np_dtype(values\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m--> 292\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_isna_string_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minf_as_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minf_as_na\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmM\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;66;03m# this is the NaT pattern\u001b[39;00m\n\u001b[1;32m    295\u001b[0m     result \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m iNaT\n",
      "File \u001b[0;32m~/data-engineering-zoomcamp-2024/.venv/lib/python3.11/site-packages/pandas/core/dtypes/missing.py:313\u001b[0m, in \u001b[0;36m_isna_string_dtype\u001b[0;34m(values, inf_as_na)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m--> 313\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mlibmissing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misnaobj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minf_as_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minf_as_na\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    315\u001b[0m         \u001b[38;5;66;03m# 0-D, reached via e.g. mask_missing\u001b[39;00m\n\u001b[1;32m    316\u001b[0m         result \u001b[38;5;241m=\u001b[39m libmissing\u001b[38;5;241m.\u001b[39misnaobj(values\u001b[38;5;241m.\u001b[39mravel(), inf_as_na\u001b[38;5;241m=\u001b[39minf_as_na)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_yellow = pd.DataFrame()\n",
    "for year in [2019, 2020]:\n",
    "    for month in range(1, 13):\n",
    "        df_yellow = pd.concat((df_yellow, pd.read_parquet(f\"~/downloads/yellow_tripdata_{year}-{month:02}.parquet\")))\n",
    "\n",
    "df_yellow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.459844e+07</td>\n",
       "      <td>84598444</td>\n",
       "      <td>84598444</td>\n",
       "      <td>8.415406e+07</td>\n",
       "      <td>8.459844e+07</td>\n",
       "      <td>8.415406e+07</td>\n",
       "      <td>8.459844e+07</td>\n",
       "      <td>8.459844e+07</td>\n",
       "      <td>8.459844e+07</td>\n",
       "      <td>8.459844e+07</td>\n",
       "      <td>8.459844e+07</td>\n",
       "      <td>8.459844e+07</td>\n",
       "      <td>8.459844e+07</td>\n",
       "      <td>8.459844e+07</td>\n",
       "      <td>8.459844e+07</td>\n",
       "      <td>8.459844e+07</td>\n",
       "      <td>7.929784e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.647355e+00</td>\n",
       "      <td>2019-06-27 04:01:11.238375</td>\n",
       "      <td>2019-06-27 04:19:15.271857</td>\n",
       "      <td>1.562665e+00</td>\n",
       "      <td>3.018351e+00</td>\n",
       "      <td>1.061298e+00</td>\n",
       "      <td>1.630973e+02</td>\n",
       "      <td>1.612823e+02</td>\n",
       "      <td>1.282589e+00</td>\n",
       "      <td>1.341264e+01</td>\n",
       "      <td>1.090265e+00</td>\n",
       "      <td>4.942546e-01</td>\n",
       "      <td>2.190079e+00</td>\n",
       "      <td>3.868694e-01</td>\n",
       "      <td>2.986066e-01</td>\n",
       "      <td>1.919230e+01</td>\n",
       "      <td>2.194992e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2001-01-01 00:02:08</td>\n",
       "      <td>2001-01-01 01:00:02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-3.726453e+04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.856000e+03</td>\n",
       "      <td>-6.000000e+01</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-2.210000e+02</td>\n",
       "      <td>-7.000000e+01</td>\n",
       "      <td>-3.000000e-01</td>\n",
       "      <td>-1.871800e+03</td>\n",
       "      <td>-2.500000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2019-03-26 07:34:29.750000</td>\n",
       "      <td>2019-03-26 07:50:15.750000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.800000e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.140000e+02</td>\n",
       "      <td>1.070000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.500000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.000000e-01</td>\n",
       "      <td>1.115000e+01</td>\n",
       "      <td>2.500000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2019-06-20 17:52:30</td>\n",
       "      <td>2019-06-20 18:14:22</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.630000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.620000e+02</td>\n",
       "      <td>1.620000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.500000e+00</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>1.860000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.000000e-01</td>\n",
       "      <td>1.475000e+01</td>\n",
       "      <td>2.500000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2019-09-30 07:54:16</td>\n",
       "      <td>2019-09-30 08:09:13.250000</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>3.080000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.330000e+02</td>\n",
       "      <td>2.330000e+02</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.500000e+01</td>\n",
       "      <td>2.500000e+00</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>2.950000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.000000e-01</td>\n",
       "      <td>2.076000e+01</td>\n",
       "      <td>2.500000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>2090-12-31 06:41:26</td>\n",
       "      <td>2090-12-31 07:18:49</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>4.597722e+04</td>\n",
       "      <td>9.900000e+01</td>\n",
       "      <td>2.650000e+02</td>\n",
       "      <td>2.650000e+02</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>9.432748e+05</td>\n",
       "      <td>5.353800e+02</td>\n",
       "      <td>2.124200e+02</td>\n",
       "      <td>1.414920e+05</td>\n",
       "      <td>3.288000e+03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.084772e+06</td>\n",
       "      <td>4.500000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.972603e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.207908e+00</td>\n",
       "      <td>8.093902e+00</td>\n",
       "      <td>7.596134e-01</td>\n",
       "      <td>6.604659e+01</td>\n",
       "      <td>7.027667e+01</td>\n",
       "      <td>4.868767e-01</td>\n",
       "      <td>1.741767e+02</td>\n",
       "      <td>1.250638e+00</td>\n",
       "      <td>6.853044e-02</td>\n",
       "      <td>1.563900e+01</td>\n",
       "      <td>1.823344e+00</td>\n",
       "      <td>2.787316e-02</td>\n",
       "      <td>1.838775e+02</td>\n",
       "      <td>8.296499e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           VendorID        tpep_pickup_datetime       tpep_dropoff_datetime  \\\n",
       "count  8.459844e+07                    84598444                    84598444   \n",
       "mean   1.647355e+00  2019-06-27 04:01:11.238375  2019-06-27 04:19:15.271857   \n",
       "min    1.000000e+00         2001-01-01 00:02:08         2001-01-01 01:00:02   \n",
       "25%    1.000000e+00  2019-03-26 07:34:29.750000  2019-03-26 07:50:15.750000   \n",
       "50%    2.000000e+00         2019-06-20 17:52:30         2019-06-20 18:14:22   \n",
       "75%    2.000000e+00         2019-09-30 07:54:16  2019-09-30 08:09:13.250000   \n",
       "max    5.000000e+00         2090-12-31 06:41:26         2090-12-31 07:18:49   \n",
       "std    4.972603e-01                         NaN                         NaN   \n",
       "\n",
       "       passenger_count  trip_distance    RatecodeID  PULocationID  \\\n",
       "count     8.415406e+07   8.459844e+07  8.415406e+07  8.459844e+07   \n",
       "mean      1.562665e+00   3.018351e+00  1.061298e+00  1.630973e+02   \n",
       "min       0.000000e+00  -3.726453e+04  1.000000e+00  1.000000e+00   \n",
       "25%       1.000000e+00   9.800000e-01  1.000000e+00  1.140000e+02   \n",
       "50%       1.000000e+00   1.630000e+00  1.000000e+00  1.620000e+02   \n",
       "75%       2.000000e+00   3.080000e+00  1.000000e+00  2.330000e+02   \n",
       "max       9.000000e+00   4.597722e+04  9.900000e+01  2.650000e+02   \n",
       "std       1.207908e+00   8.093902e+00  7.596134e-01  6.604659e+01   \n",
       "\n",
       "       DOLocationID  payment_type   fare_amount         extra       mta_tax  \\\n",
       "count  8.459844e+07  8.459844e+07  8.459844e+07  8.459844e+07  8.459844e+07   \n",
       "mean   1.612823e+02  1.282589e+00  1.341264e+01  1.090265e+00  4.942546e-01   \n",
       "min    1.000000e+00  0.000000e+00 -1.856000e+03 -6.000000e+01 -5.000000e-01   \n",
       "25%    1.070000e+02  1.000000e+00  6.500000e+00  0.000000e+00  5.000000e-01   \n",
       "50%    1.620000e+02  1.000000e+00  9.500000e+00  5.000000e-01  5.000000e-01   \n",
       "75%    2.330000e+02  2.000000e+00  1.500000e+01  2.500000e+00  5.000000e-01   \n",
       "max    2.650000e+02  5.000000e+00  9.432748e+05  5.353800e+02  2.124200e+02   \n",
       "std    7.027667e+01  4.868767e-01  1.741767e+02  1.250638e+00  6.853044e-02   \n",
       "\n",
       "         tip_amount  tolls_amount  improvement_surcharge  total_amount  \\\n",
       "count  8.459844e+07  8.459844e+07           8.459844e+07  8.459844e+07   \n",
       "mean   2.190079e+00  3.868694e-01           2.986066e-01  1.919230e+01   \n",
       "min   -2.210000e+02 -7.000000e+01          -3.000000e-01 -1.871800e+03   \n",
       "25%    0.000000e+00  0.000000e+00           3.000000e-01  1.115000e+01   \n",
       "50%    1.860000e+00  0.000000e+00           3.000000e-01  1.475000e+01   \n",
       "75%    2.950000e+00  0.000000e+00           3.000000e-01  2.076000e+01   \n",
       "max    1.414920e+05  3.288000e+03           1.000000e+00  1.084772e+06   \n",
       "std    1.563900e+01  1.823344e+00           2.787316e-02  1.838775e+02   \n",
       "\n",
       "       congestion_surcharge  \n",
       "count          7.929784e+07  \n",
       "mean           2.194992e+00  \n",
       "min           -2.500000e+00  \n",
       "25%            2.500000e+00  \n",
       "50%            2.500000e+00  \n",
       "75%            2.500000e+00  \n",
       "max            4.500000e+00  \n",
       "std            8.296499e-01  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yellow.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 84598444 entries, 0 to 6896316\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Dtype         \n",
      "---  ------                 -----         \n",
      " 0   VendorID               int64         \n",
      " 1   tpep_pickup_datetime   datetime64[us]\n",
      " 2   tpep_dropoff_datetime  datetime64[us]\n",
      " 3   passenger_count        float64       \n",
      " 4   trip_distance          float64       \n",
      " 5   RatecodeID             float64       \n",
      " 6   store_and_fwd_flag     object        \n",
      " 7   PULocationID           int64         \n",
      " 8   DOLocationID           int64         \n",
      " 9   payment_type           int64         \n",
      " 10  fare_amount            float64       \n",
      " 11  extra                  float64       \n",
      " 12  mta_tax                float64       \n",
      " 13  tip_amount             float64       \n",
      " 14  tolls_amount           float64       \n",
      " 15  improvement_surcharge  float64       \n",
      " 16  total_amount           float64       \n",
      " 17  congestion_surcharge   float64       \n",
      " 18  airport_fee            object        \n",
      "dtypes: datetime64[us](2), float64(11), int64(4), object(2)\n",
      "memory usage: 12.6+ GB\n"
     ]
    }
   ],
   "source": [
    "df_yellow.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yellow_cast = df_yellow.convert_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 84598444 entries, 0 to 6896316\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Dtype         \n",
      "---  ------                 -----         \n",
      " 0   VendorID               Int64         \n",
      " 1   tpep_pickup_datetime   datetime64[us]\n",
      " 2   tpep_dropoff_datetime  datetime64[us]\n",
      " 3   passenger_count        Int64         \n",
      " 4   trip_distance          Float64       \n",
      " 5   RatecodeID             Int64         \n",
      " 6   store_and_fwd_flag     string        \n",
      " 7   PULocationID           Int64         \n",
      " 8   DOLocationID           Int64         \n",
      " 9   payment_type           Int64         \n",
      " 10  fare_amount            Float64       \n",
      " 11  extra                  Float64       \n",
      " 12  mta_tax                Float64       \n",
      " 13  tip_amount             Float64       \n",
      " 14  tolls_amount           Float64       \n",
      " 15  improvement_surcharge  Float64       \n",
      " 16  total_amount           Float64       \n",
      " 17  congestion_surcharge   Float64       \n",
      " 18  airport_fee            object        \n",
      "dtypes: Float64(9), Int64(6), datetime64[us](2), object(1), string(1)\n",
      "memory usage: 13.8+ GB\n"
     ]
    }
   ],
   "source": [
    "df_yellow_cast.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Green"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y0/5f2jwbwn27ng96snkjkltj6h0000gn/T/ipykernel_84497/2968789713.py:3: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_green = pd.concat((df_green, pd.read_parquet(f\"~/downloads/green_tripdata_2019-{i:02}.parquet\")))\n",
      "/var/folders/y0/5f2jwbwn27ng96snkjkltj6h0000gn/T/ipykernel_84497/2968789713.py:3: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_green = pd.concat((df_green, pd.read_parquet(f\"~/downloads/green_tripdata_2019-{i:02}.parquet\")))\n",
      "/var/folders/y0/5f2jwbwn27ng96snkjkltj6h0000gn/T/ipykernel_84497/2968789713.py:3: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_green = pd.concat((df_green, pd.read_parquet(f\"~/downloads/green_tripdata_2019-{i:02}.parquet\")))\n",
      "/var/folders/y0/5f2jwbwn27ng96snkjkltj6h0000gn/T/ipykernel_84497/2968789713.py:3: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_green = pd.concat((df_green, pd.read_parquet(f\"~/downloads/green_tripdata_2019-{i:02}.parquet\")))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>lpep_dropoff_datetime</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>ehail_fee</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-12-21 15:17:29</td>\n",
       "      <td>2018-12-21 15:18:57</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>264</td>\n",
       "      <td>264</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.30</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-01 00:10:16</td>\n",
       "      <td>2019-01-01 00:16:32</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97</td>\n",
       "      <td>49</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.86</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.30</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-01 00:27:11</td>\n",
       "      <td>2019-01-01 00:31:38</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49</td>\n",
       "      <td>189</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-01 00:46:20</td>\n",
       "      <td>2019-01-01 01:04:54</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>189</td>\n",
       "      <td>17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.68</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>19.71</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-01 00:19:06</td>\n",
       "      <td>2019-01-01 00:39:43</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>82</td>\n",
       "      <td>258</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.53</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>19.30</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID lpep_pickup_datetime lpep_dropoff_datetime store_and_fwd_flag  \\\n",
       "0         2  2018-12-21 15:17:29   2018-12-21 15:18:57                  N   \n",
       "1         2  2019-01-01 00:10:16   2019-01-01 00:16:32                  N   \n",
       "2         2  2019-01-01 00:27:11   2019-01-01 00:31:38                  N   \n",
       "3         2  2019-01-01 00:46:20   2019-01-01 01:04:54                  N   \n",
       "4         2  2019-01-01 00:19:06   2019-01-01 00:39:43                  N   \n",
       "\n",
       "   RatecodeID  PULocationID  DOLocationID  passenger_count  trip_distance  \\\n",
       "0         1.0           264           264              5.0           0.00   \n",
       "1         1.0            97            49              2.0           0.86   \n",
       "2         1.0            49           189              2.0           0.66   \n",
       "3         1.0           189            17              2.0           2.68   \n",
       "4         1.0            82           258              1.0           4.53   \n",
       "\n",
       "   fare_amount  extra  mta_tax  tip_amount  tolls_amount  ehail_fee  \\\n",
       "0          3.0    0.5      0.5        0.00           0.0        NaN   \n",
       "1          6.0    0.5      0.5        0.00           0.0        NaN   \n",
       "2          4.5    0.5      0.5        0.00           0.0        NaN   \n",
       "3         13.5    0.5      0.5        2.96           0.0        NaN   \n",
       "4         18.0    0.5      0.5        0.00           0.0        NaN   \n",
       "\n",
       "   improvement_surcharge  total_amount  payment_type  trip_type  \\\n",
       "0                    0.3          4.30           2.0        1.0   \n",
       "1                    0.3          7.30           2.0        1.0   \n",
       "2                    0.3          5.80           1.0        1.0   \n",
       "3                    0.3         19.71           1.0        1.0   \n",
       "4                    0.3         19.30           2.0        1.0   \n",
       "\n",
       "   congestion_surcharge  \n",
       "0                   NaN  \n",
       "1                   NaN  \n",
       "2                   NaN  \n",
       "3                   NaN  \n",
       "4                   NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_green = pd.DataFrame()\n",
    "for year in [2019, 2020]:\n",
    "    for month in range(1, 13):\n",
    "        df_green = pd.concat((df_green, pd.read_parquet(f\"~/downloads/green_tripdata_{year}-{month:02}.parquet\")))\n",
    "\n",
    "df_green.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>lpep_dropoff_datetime</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>ehail_fee</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.300985e+06</td>\n",
       "      <td>6300985</td>\n",
       "      <td>6300985</td>\n",
       "      <td>5.627847e+06</td>\n",
       "      <td>6.300985e+06</td>\n",
       "      <td>6.300985e+06</td>\n",
       "      <td>5.627847e+06</td>\n",
       "      <td>6.300985e+06</td>\n",
       "      <td>6.300985e+06</td>\n",
       "      <td>6.300985e+06</td>\n",
       "      <td>6.300985e+06</td>\n",
       "      <td>6.300985e+06</td>\n",
       "      <td>6.300985e+06</td>\n",
       "      <td>2217.000000</td>\n",
       "      <td>6.300983e+06</td>\n",
       "      <td>6.300985e+06</td>\n",
       "      <td>5.627847e+06</td>\n",
       "      <td>5.625625e+06</td>\n",
       "      <td>5.081846e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.858115e+00</td>\n",
       "      <td>2019-06-17 04:00:22.938513</td>\n",
       "      <td>2019-06-17 04:22:31.480754</td>\n",
       "      <td>1.186903e+00</td>\n",
       "      <td>1.089954e+02</td>\n",
       "      <td>1.291969e+02</td>\n",
       "      <td>1.310472e+00</td>\n",
       "      <td>3.531442e+00</td>\n",
       "      <td>1.543698e+01</td>\n",
       "      <td>6.237331e-01</td>\n",
       "      <td>4.829754e-01</td>\n",
       "      <td>9.436765e-01</td>\n",
       "      <td>2.901362e-01</td>\n",
       "      <td>0.024628</td>\n",
       "      <td>2.583555e-01</td>\n",
       "      <td>1.832804e+01</td>\n",
       "      <td>1.439934e+00</td>\n",
       "      <td>1.044494e+00</td>\n",
       "      <td>3.975886e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2008-10-21 15:52:05</td>\n",
       "      <td>2008-10-21 15:54:26</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-2.032908e+04</td>\n",
       "      <td>-8.900000e+02</td>\n",
       "      <td>-4.500000e+00</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-9.050000e+01</td>\n",
       "      <td>-2.100000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.000000e-01</td>\n",
       "      <td>-8.903000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-2.750000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2019-03-14 18:19:19</td>\n",
       "      <td>2019-03-14 18:40:40</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.200000e+01</td>\n",
       "      <td>6.500000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.100000e+00</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000e-01</td>\n",
       "      <td>8.800000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2019-06-07 15:02:11</td>\n",
       "      <td>2019-06-07 15:26:19</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>8.200000e+01</td>\n",
       "      <td>1.290000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.050000e+00</td>\n",
       "      <td>1.050000e+01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000e-01</td>\n",
       "      <td>1.330000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2019-09-18 11:48:33</td>\n",
       "      <td>2019-09-18 12:12:00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.660000e+02</td>\n",
       "      <td>1.930000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.290000e+00</td>\n",
       "      <td>1.950000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>1.560000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000e-01</td>\n",
       "      <td>2.305000e+01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>2062-08-15 00:00:00</td>\n",
       "      <td>2062-08-15 16:34:10</td>\n",
       "      <td>9.900000e+01</td>\n",
       "      <td>2.650000e+02</td>\n",
       "      <td>2.650000e+02</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>7.784376e+04</td>\n",
       "      <td>4.011500e+03</td>\n",
       "      <td>1.375000e+01</td>\n",
       "      <td>1.733000e+01</td>\n",
       "      <td>4.410000e+02</td>\n",
       "      <td>9.355000e+02</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>4.700000e-01</td>\n",
       "      <td>4.012300e+03</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.750000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.489565e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.857558e-01</td>\n",
       "      <td>7.194994e+01</td>\n",
       "      <td>7.645506e+01</td>\n",
       "      <td>9.710610e-01</td>\n",
       "      <td>3.368059e+01</td>\n",
       "      <td>1.413383e+01</td>\n",
       "      <td>9.581348e-01</td>\n",
       "      <td>9.888854e-02</td>\n",
       "      <td>1.984789e+00</td>\n",
       "      <td>1.437311e+00</td>\n",
       "      <td>0.217805</td>\n",
       "      <td>1.061479e-01</td>\n",
       "      <td>1.546341e+01</td>\n",
       "      <td>5.202182e-01</td>\n",
       "      <td>2.061909e-01</td>\n",
       "      <td>9.670983e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           VendorID        lpep_pickup_datetime       lpep_dropoff_datetime  \\\n",
       "count  6.300985e+06                     6300985                     6300985   \n",
       "mean   1.858115e+00  2019-06-17 04:00:22.938513  2019-06-17 04:22:31.480754   \n",
       "min    1.000000e+00         2008-10-21 15:52:05         2008-10-21 15:54:26   \n",
       "25%    2.000000e+00         2019-03-14 18:19:19         2019-03-14 18:40:40   \n",
       "50%    2.000000e+00         2019-06-07 15:02:11         2019-06-07 15:26:19   \n",
       "75%    2.000000e+00         2019-09-18 11:48:33         2019-09-18 12:12:00   \n",
       "max    5.000000e+00         2062-08-15 00:00:00         2062-08-15 16:34:10   \n",
       "std    3.489565e-01                         NaN                         NaN   \n",
       "\n",
       "         RatecodeID  PULocationID  DOLocationID  passenger_count  \\\n",
       "count  5.627847e+06  6.300985e+06  6.300985e+06     5.627847e+06   \n",
       "mean   1.186903e+00  1.089954e+02  1.291969e+02     1.310472e+00   \n",
       "min    1.000000e+00  1.000000e+00  1.000000e+00     0.000000e+00   \n",
       "25%    1.000000e+00  5.200000e+01  6.500000e+01     1.000000e+00   \n",
       "50%    1.000000e+00  8.200000e+01  1.290000e+02     1.000000e+00   \n",
       "75%    1.000000e+00  1.660000e+02  1.930000e+02     1.000000e+00   \n",
       "max    9.900000e+01  2.650000e+02  2.650000e+02     9.000000e+00   \n",
       "std    8.857558e-01  7.194994e+01  7.645506e+01     9.710610e-01   \n",
       "\n",
       "       trip_distance   fare_amount         extra       mta_tax    tip_amount  \\\n",
       "count   6.300985e+06  6.300985e+06  6.300985e+06  6.300985e+06  6.300985e+06   \n",
       "mean    3.531442e+00  1.543698e+01  6.237331e-01  4.829754e-01  9.436765e-01   \n",
       "min    -2.032908e+04 -8.900000e+02 -4.500000e+00 -5.000000e-01 -9.050000e+01   \n",
       "25%     1.100000e+00  7.000000e+00  0.000000e+00  5.000000e-01  0.000000e+00   \n",
       "50%     2.050000e+00  1.050000e+01  5.000000e-01  5.000000e-01  0.000000e+00   \n",
       "75%     4.290000e+00  1.950000e+01  1.000000e+00  5.000000e-01  1.560000e+00   \n",
       "max     7.784376e+04  4.011500e+03  1.375000e+01  1.733000e+01  4.410000e+02   \n",
       "std     3.368059e+01  1.413383e+01  9.581348e-01  9.888854e-02  1.984789e+00   \n",
       "\n",
       "       tolls_amount    ehail_fee  improvement_surcharge  total_amount  \\\n",
       "count  6.300985e+06  2217.000000           6.300983e+06  6.300985e+06   \n",
       "mean   2.901362e-01     0.024628           2.583555e-01  1.832804e+01   \n",
       "min   -2.100000e+01     0.000000          -3.000000e-01 -8.903000e+02   \n",
       "25%    0.000000e+00     0.000000           3.000000e-01  8.800000e+00   \n",
       "50%    0.000000e+00     0.000000           3.000000e-01  1.330000e+01   \n",
       "75%    0.000000e+00     0.000000           3.000000e-01  2.305000e+01   \n",
       "max    9.355000e+02     1.950000           4.700000e-01  4.012300e+03   \n",
       "std    1.437311e+00     0.217805           1.061479e-01  1.546341e+01   \n",
       "\n",
       "       payment_type     trip_type  congestion_surcharge  \n",
       "count  5.627847e+06  5.625625e+06          5.081846e+06  \n",
       "mean   1.439934e+00  1.044494e+00          3.975886e-01  \n",
       "min    1.000000e+00  1.000000e+00         -2.750000e+00  \n",
       "25%    1.000000e+00  1.000000e+00          0.000000e+00  \n",
       "50%    1.000000e+00  1.000000e+00          0.000000e+00  \n",
       "75%    2.000000e+00  1.000000e+00          0.000000e+00  \n",
       "max    5.000000e+00  2.000000e+00          2.750000e+00  \n",
       "std    5.202182e-01  2.061909e-01          9.670983e-01  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_green.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6300985 entries, 0 to 455293\n",
      "Data columns (total 20 columns):\n",
      " #   Column                 Dtype         \n",
      "---  ------                 -----         \n",
      " 0   VendorID               int64         \n",
      " 1   lpep_pickup_datetime   datetime64[us]\n",
      " 2   lpep_dropoff_datetime  datetime64[us]\n",
      " 3   store_and_fwd_flag     object        \n",
      " 4   RatecodeID             float64       \n",
      " 5   PULocationID           int64         \n",
      " 6   DOLocationID           int64         \n",
      " 7   passenger_count        float64       \n",
      " 8   trip_distance          float64       \n",
      " 9   fare_amount            float64       \n",
      " 10  extra                  float64       \n",
      " 11  mta_tax                float64       \n",
      " 12  tip_amount             float64       \n",
      " 13  tolls_amount           float64       \n",
      " 14  ehail_fee              float64       \n",
      " 15  improvement_surcharge  float64       \n",
      " 16  total_amount           float64       \n",
      " 17  payment_type           float64       \n",
      " 18  trip_type              float64       \n",
      " 19  congestion_surcharge   float64       \n",
      "dtypes: datetime64[us](2), float64(14), int64(3), object(1)\n",
      "memory usage: 1009.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_green.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green_cast = df_green.convert_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6300985 entries, 0 to 455293\n",
      "Data columns (total 20 columns):\n",
      " #   Column                 Dtype         \n",
      "---  ------                 -----         \n",
      " 0   VendorID               Int64         \n",
      " 1   lpep_pickup_datetime   datetime64[us]\n",
      " 2   lpep_dropoff_datetime  datetime64[us]\n",
      " 3   store_and_fwd_flag     string        \n",
      " 4   RatecodeID             Int64         \n",
      " 5   PULocationID           Int64         \n",
      " 6   DOLocationID           Int64         \n",
      " 7   passenger_count        Int64         \n",
      " 8   trip_distance          Float64       \n",
      " 9   fare_amount            Float64       \n",
      " 10  extra                  Float64       \n",
      " 11  mta_tax                Float64       \n",
      " 12  tip_amount             Float64       \n",
      " 13  tolls_amount           Float64       \n",
      " 14  ehail_fee              Float64       \n",
      " 15  improvement_surcharge  Float64       \n",
      " 16  total_amount           Float64       \n",
      " 17  payment_type           Int64         \n",
      " 18  trip_type              Int64         \n",
      " 19  congestion_surcharge   Float64       \n",
      "dtypes: Float64(10), Int64(7), datetime64[us](2), string(1)\n",
      "memory usage: 1.1 GB\n"
     ]
    }
   ],
   "source": [
    "df_green_cast.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
